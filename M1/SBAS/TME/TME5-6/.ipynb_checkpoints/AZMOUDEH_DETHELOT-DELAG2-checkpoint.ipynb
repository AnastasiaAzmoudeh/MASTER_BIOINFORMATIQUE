{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzMJ2QtGxpkq"
   },
   "source": [
    "<h1><b>Statistique en Bioinformatique : </b> TME 5 et 6 </h1>\n",
    "<br>\n",
    "L’objectif de ce TME est:\n",
    "<br>\n",
    "<ul>\n",
    "<li> implémenter l'algorithme de Viterbi et l'estimation des paramètres (en utilisant le Viterbi training)\n",
    "pour l'exemple du occasionally dishonest casino.   </li> \n",
    "</ul>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">\n",
    "<p><b>Soumission</b></p>\n",
    "<ul>\n",
    "<li>Renomer le fichier TME5_6.ipynb pour NomEtudiant1_NomEtudiant2.ipynb </li>\n",
    "<li>Soumettre via moodle </li>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiohDpWCxpkv"
   },
   "source": [
    "Nom etudiant 1 : Anastasia AZMOUDEH\n",
    "<br>\n",
    "Nom etudiant 2 : Késia DETHELOT-DELAG\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6n5Srpuxpkv"
   },
   "source": [
    "<h3>Introduction</h3>\n",
    "Un casino parfois malhonnête (occasionally dishonest casino) utilise 2 types de pieces : fair et unfair. <br>\n",
    "La matrice de transition entre les états cachés est:<br>\n",
    "${\\cal S}=\\{F,U\\}$ (fair, unfair):\n",
    "$$\n",
    "p = \\left(\n",
    "\\begin{array}{cc}\n",
    "0.99 & 0.01\\\\\n",
    "0.05 & 0.95\n",
    "\\end{array}\n",
    "\\right)\\ ,\n",
    "$$\n",
    "\n",
    "les probabilités d'émission des symboles \n",
    "${\\cal O} = \\{H,T\\}$ (head, tail):\n",
    "\\begin{eqnarray}\n",
    "e_F(H) =  0.5 &\\ \\ \\ \\ &\n",
    "e_F(T) = 0.5 \\nonumber\\\\\n",
    "e_U(H) = 0.9 &\\ \\ \\ \\ &\n",
    "e_U(T) = 0.1 \\nonumber\n",
    "\\end{eqnarray}\n",
    "\n",
    "<br> Et la condition initiale $\\pi^{(0)} = (0.999,0.001)$ (le jeux commence presque toujours avec le pieces juste (fair)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKz1fEeIxpkw"
   },
   "source": [
    "<b>Exercice 1</b>:\n",
    "<u>Simulation</u>: Écrire une fonction qui simule $T$ jets de pièces. \n",
    "La fonction renverra un tableau à deux colonnes correspondant \n",
    "aux valeurs simulées pour les états cachés $X_t$ \n",
    "(type de dés utilisée, “F” ou “U”) et aux symboles observées $Y_t$ \n",
    "(résultat du jet de dés, “H” ou “T”). On simulera une séquence\n",
    "de longueur 2000 qu'on gardera pour les applications ultérieures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "txZ2YCPbxpkx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#states\n",
    "S = { 0:'F',1 :'U'}\n",
    "\n",
    "#transition probability matrix\n",
    "Pij = np.array([[0.99,0.01], [0.05,0.95]])\n",
    "\n",
    "#emision symbols \n",
    "O = {0:'H', 1: 'T'}\n",
    "\n",
    "#emission probability matrix\n",
    "Ei = np.array([[0.5,0.5], [0.9,0.1]]) #ça aurait dû être Eio\n",
    "\n",
    "# initial Condition\n",
    "pi0=np.array([0.999,0.001])\n",
    "\n",
    "#number of jets\n",
    "T = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5OIqLuzAxpkz",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "U T\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "U H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "U H\n",
      "U H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U T\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "U H\n",
      "F H\n",
      "U H\n",
      "U T\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F H\n",
      "F H\n",
      "F T\n",
      "F T\n",
      "F H\n",
      "F T\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Fonction qui simule T jets de pieces\n",
    "def jets(T, pi0, Eij, Pij):\n",
    "    \"\"\"\n",
    "      simulation of occasionally dishonest casino\n",
    "      input1 T: number of jets\n",
    "      input2 pi0: initial condition\n",
    "      input3 Eij: emission probability matrix\n",
    "      input4 Pij: transition probability matrix\n",
    "      output1 jetsRes: matrix |2xT| containing simulations\n",
    "    \"\"\"\n",
    "\n",
    "    # Creation du tableau\n",
    "    jetsRes = np.zeros((T,len(pi0)),dtype=int)\n",
    "\n",
    "    \n",
    "    # création d'une matrice pour les observations avec des chiffres\n",
    "    Traj_ind = []\n",
    "    \n",
    "    # création d'une séquence aléatoire de longueur T \n",
    "    nb_alea = []\n",
    "    for i in range (T): \n",
    "        alea = random.random()\n",
    "        nb_alea.append(alea)\n",
    "    \n",
    "#     normalisation de la matrice\n",
    "    taille_Pi_0 = len(pi0)\n",
    "    Pi_0_normal = np.zeros(taille_Pi_0)\n",
    "    somme = np.sum(pi0)\n",
    "\n",
    "\n",
    "    for i in range (len(pi0)): \n",
    "        Pi_0_normal[i]= pi0[i]/somme\n",
    "\n",
    "\n",
    "    # création de la matrice pi' (avec les sommes cumulées croissantes)\n",
    "    Pi_0_bis = np.zeros(taille_Pi_0)\n",
    "    Pi_0_bis[0]= Pi_0_normal[0]\n",
    "    for i in range (1,taille_Pi_0): \n",
    "        Pi_0_bis[i]= Pi_0_normal[i] + Pi_0_bis[i-1]\n",
    "\n",
    "    \n",
    "    # normalisation de la matrice Pij \n",
    "    for i in range (int(len(Pij))): \n",
    "        Somme = np.sum(Pij[i])\n",
    "        for j in range (int(len (Pij[i]))):\n",
    "            Pij[i][j]= (Pij[i][j])/Somme   \n",
    "    \n",
    "    # création de la matrice P' (avec les sommes cumulées croissantes)\n",
    "    taille_P = len(Pij)\n",
    "    P_bis = np.zeros((taille_P, taille_P))\n",
    "    for i in range(taille_P): \n",
    "        for j in range(taille_P): \n",
    "            if j == 0 : \n",
    "                P_bis[i][j]=Pij[i][j]\n",
    "            else : \n",
    "                P_bis[i][j]=Pij[i][j] + P_bis[i][j-1]\n",
    "\n",
    "    # trouver le premier état\n",
    "    premier = nb_alea[0]\n",
    "    if premier < Pi_0_bis[0]:\n",
    "        Traj_ind.append('0')\n",
    "    \n",
    "    else: \n",
    "        Traj_ind.append('1')\n",
    "        \n",
    "    \n",
    "    # trouver les états suivants\n",
    "    for i in range(1, T): \n",
    "        if Traj_ind[-1] == \"0\": \n",
    "            indice = 0\n",
    "        if Traj_ind[-1] == \"1\": \n",
    "            indice = 1\n",
    "\n",
    "        suivant = nb_alea[i]\n",
    "        if suivant <= P_bis[indice][0]:\n",
    "            Traj_ind.append('0')\n",
    "        else: \n",
    "            Traj_ind.append('1')\n",
    "\n",
    "    Obs_ind = []\n",
    "    \n",
    "    \n",
    "    for i in range(T): \n",
    "        if Traj_ind[i]== '0': \n",
    "            liste = [\"0\", \"1\"]\n",
    "            e = random.choices(liste, weights = (Eij[0][0], Eij[0][1]), k = 1)   \n",
    "            Obs_ind.append(e)\n",
    "          \n",
    "    \n",
    "        if Traj_ind[i]== '1': \n",
    "            liste = [\"0\", \"1\"]\n",
    "            e = random.choices(liste, weights = (Eij[1][0], Eij[1][1]), k = 1)\n",
    "            Obs_ind.append(e)\n",
    "\n",
    "    Obs_ind = sum(Obs_ind, []) # pour transformer liste de listes en une seule et unique liste \n",
    "    \n",
    "    for i in range (len(jetsRes)): \n",
    "        jetsRes[i][0]= Traj_ind[i]\n",
    "        jetsRes[i][1]= Obs_ind[i]\n",
    "   \n",
    "    return jetsRes\n",
    "\n",
    "\n",
    "\n",
    "def printSimulation(resultat):\n",
    "    for i in resultat : \n",
    "        print (S[i[0]], O[i[1]])\n",
    "        \n",
    "jetsRes = jets(T, pi0, Ei, Pij) \n",
    "# print(jetsRes)\n",
    "printSimulation(jetsRes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpGzwVdIxpk0"
   },
   "source": [
    "<b>Exercice 2</b>: <u>Algorithme de Viterbi </u>: Écrire une fonction qui permet\n",
    "de déterminer la séquence $(i^\\star_t)_{t=0:T}$ d'états cachés\n",
    "plus probable, ainsi que sa probabilité. Pour tester votre fonction utiliser le résultat de la \n",
    "simulation (2éme colonne) de la question 1. Comparer $(i^\\star_t)_{t=0:T}$ avec\n",
    "les vrais états cachés (1ère colonne de la simulation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur d'estimation de viterbi:\n",
      "10.8 %\n",
      "Probabilité estimé:\n",
      "0.0\n",
      "=========================================================\n",
      "erreur d'estimation de viterbi:\n",
      "9.049999999999999 %\n",
      "Probabilité estimé:\n",
      "-1389.7987288672582\n"
     ]
    }
   ],
   "source": [
    "# Algorithme de Viterbi\n",
    "import operator\n",
    "\n",
    "def viterbi(jets, Pij, Ei, pi0, nS, nO, enLog):\n",
    "    \"\"\"\n",
    "    Implement Viterbi algorithm\n",
    "    input1 jets: matrix |2xT| containing simulations\n",
    "    input4 Pij: transition probability matrix\n",
    "    input3 Ei: emission probability matrix\n",
    "    input4 pi0: initial condition\n",
    "    input5 nS: number of states\n",
    "    input6 nO: number of observations\n",
    "    input7 enLog: bool, when True we apply log to avoid underflow\n",
    "    output1 i_star: most problable path\n",
    "    output2 prob: probability associated to the most problable path\n",
    "    \"\"\"\n",
    "    \n",
    "    obs = jets[:,1] # les observations\n",
    "\n",
    "    T = len(obs) #Nombre d'observations (longueur des observations)\n",
    "    etat = jets[:,0] # les états cachés\n",
    "    \n",
    "    i_star = np.zeros((T))\n",
    "    prob = 1\n",
    "    path = np.zeros((T))\n",
    "    \n",
    "    # avec le log \n",
    "    if enLog: \n",
    "        # pour t = 1\n",
    "        from_F = np.log(pi0[0]) + np.log(Ei[0][obs[0]])\n",
    "        from_U = np.log(pi0[1]) + np.log(Ei[1][obs[0]])\n",
    "        path[0] = max(from_F, from_U)\n",
    "    \n",
    "        if path[0] == from_F : \n",
    "            i_star[0] = 0\n",
    "        else: \n",
    "            i_star[0] = 1\n",
    "\n",
    "        # pour les autres t>1    \n",
    "        for i in range(1,T): \n",
    "            from_F = np.log(Ei[0][obs[i]]) + max (from_F + np.log(Pij[0][0]), from_U + np.log(Pij [1][0]))\n",
    "            from_U = np.log(Ei[1][obs[i]]) + max (from_F + np.log(Pij[0][1]), from_U + np.log(Pij [1][1]))\n",
    "            path[i]= max(from_F, from_U)\n",
    "\n",
    "            if path[i] == from_F : \n",
    "                i_star[i] = 0\n",
    "            else: \n",
    "                i_star[i] = 1\n",
    "    \n",
    "    # sans le log \n",
    "    else: \n",
    "        # pour t = 1\n",
    "        from_F = pi0[0] * Ei[0][obs[0]]\n",
    "        from_U = pi0[1] * Ei[1][obs[0]]\n",
    "        path[0] = max(from_F, from_U)\n",
    "\n",
    "        if path[0] == from_F : \n",
    "            i_star[0] = 0\n",
    "        else: \n",
    "            i_star[0] = 1\n",
    "\n",
    "        # pour les autres t>1    \n",
    "        for i in range(1,T): \n",
    "            from_F = Ei[0][obs[i]] * max (from_F * Pij[0][0], from_U * Pij [1][0])\n",
    "            from_U = Ei[1][obs[i]] * max (from_F * Pij[0][1], from_U * Pij [1][1])\n",
    "            path[i]= max(from_F, from_U)\n",
    "\n",
    "            if path[i] == from_F : \n",
    "                i_star[i] = 0\n",
    "            else: \n",
    "                i_star[i] = 1\n",
    "            \n",
    "    prob = path[-1]\n",
    "    \n",
    "    return i_star, prob\n",
    "\n",
    "def analyseResultats(jets, estimation):    \n",
    "    \"\"\"\n",
    "    Compare expected and obtained paths\n",
    "    input1 jets: expected path\n",
    "    input2 estimation: obtained path\n",
    "    output1 error: percentage error\n",
    "    \"\"\"\n",
    "    l = len(jets)\n",
    "    faute = 0\n",
    "    \n",
    "#     print(jets)\n",
    "#     print(estimation)\n",
    "    \n",
    "    etat = jets[:,0]\n",
    "    \n",
    "    for i in range (l): \n",
    "        if etat[i] != estimation [i]: \n",
    "            faute += 1\n",
    "    error = (faute/l)*100\n",
    "        \n",
    "    return error\n",
    "\n",
    "i_est, P_est = viterbi(jetsRes, Pij, Ei, pi0, 2, 2, False)\n",
    "error = analyseResultats(jetsRes, i_est)\n",
    "print('erreur d\\'estimation de viterbi:')\n",
    "print(error,'%')\n",
    "print('Probabilité estimé:')\n",
    "print(P_est)\n",
    "\n",
    "# En utilisant le log\n",
    "print(\"=========================================================\")\n",
    "i_est2, P_est2 = viterbi(jetsRes, Pij, Ei, pi0, 2, 2, True)\n",
    "error2 = analyseResultats(jetsRes, i_est2)\n",
    "print('erreur d\\'estimation de viterbi:')\n",
    "print(error2,'%')\n",
    "print('Probabilité estimé:')\n",
    "print(P_est2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7NimDYwxpk2"
   },
   "source": [
    "<b>Exercice 3</b>: <u>Estimation des paramètres</u>\n",
    "<br>\n",
    "3.1) Écrire une fonction qu'utilise tous les résultats de la simulation\n",
    "(états et symboles) pour compter les nombres d'occurrence $N_{ij}$ est $M_{iO}$ définis en cours. Estimer $P_{ij}$ est $E_i(O)$. Attention, pour éviter les probabilités à zéro nous allons utiliser les pseudo-count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "msq33Rxjxpk2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pij estimé:\n",
      "[[0.66367209 0.35779817]\n",
      " [0.33632791 0.64220183]]\n",
      "\n",
      "Eio estimé:\n",
      "[[0.5114104  0.36391437]\n",
      " [0.4885896  0.63608563]]\n",
      "\n",
      "pi0 estimé:\n",
      "[0.891 0.109]\n"
     ]
    }
   ],
   "source": [
    "# Estimation de Parametres par contage\n",
    "def nombresOccurrence(jets, nS, nO):\n",
    "    \"\"\"\n",
    "    Parameter estimation\n",
    "    input1 jets: matrix |2xT| containing data\n",
    "    input2 nS: number of states\n",
    "    input3 nO: number of observations\n",
    "    output1 Nij: transition probability matrix\n",
    "    output2 Mio: emission probability matrix\n",
    "    output3 pi0: initial condition \n",
    "    \"\"\"\n",
    "\n",
    "    Nij = np.ones((nS,nS)) #pseudo-count = 1\n",
    "    Mio = np.ones((nS,nO))  #pseudo-count = 1\n",
    "    pi0 = np.ones((nS))\n",
    "    \n",
    "    Caches = jets[:,0] \n",
    "    Obs    = jets[:,1]\n",
    "   \n",
    "    \n",
    "    # estimation de la matrice de trasnition \n",
    "    Nb_FF = 0\n",
    "    Nb_FU = 0  \n",
    "    Nb_UU = 0 \n",
    "    Nb_UF = 0\n",
    "    erreur = 0\n",
    "    \n",
    "    \n",
    "    for i in range (len(Caches)-1): \n",
    "#         print(\"i\" , i)\n",
    "        if Caches[i] == 0 and Caches[i+1] == 0: \n",
    "#             print(\"FF\")\n",
    "            Nb_FF +=1\n",
    "        elif Caches[i] == 0 and Caches[i+1] == 1:\n",
    "            Nb_FU +=1\n",
    "#             print(\"FU\")\n",
    "        elif Caches[i] == 1 and Caches[i+1] == 1:\n",
    "#             print(\"UU\")\n",
    "            Nb_UU +=1\n",
    "        elif Caches[i] == 1 and Caches[i+1] == 0:\n",
    "#             print(\"UF\")\n",
    "            Nb_UF +=1\n",
    "        else : \n",
    "            erreur += 1  \n",
    "            \n",
    "    # erreur doit être égale à 0\n",
    "#     print(\"erreur\", erreur) # pour vérifier que toutes les transitions sont prises en compte et donc qu'il n'y a pas d'erreur\n",
    "#     print(np.sum([Nb_FF,Nb_FU,Nb_UU,Nb_UF])) # on vérifie que la somme vale (len-1)\n",
    "    \n",
    "    Nij[0][0] += (Nb_FF)/ (Nb_FF + Nb_UF)\n",
    "    Nij[1][0] += (1 - ((Nb_FF)/ (Nb_FF + Nb_UF)))\n",
    "    Nij[1][1] += ( Nb_UU)/ (Nb_UU + Nb_FU)\n",
    "    Nij[0][1] += (1 - ( Nb_UU)/ (Nb_UU + Nb_FU))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # estimation de la matrice d'emission \n",
    "    erreur_compte = 0\n",
    "    Nb_F = 0\n",
    "    Nb_U = 0\n",
    "    \n",
    "    \n",
    "    for i in range (len(Caches)): \n",
    "        if Caches[i] == 0: \n",
    "            Nb_F += 1\n",
    "        elif Caches[i] == 1: \n",
    "            Nb_U += 1\n",
    "        else: \n",
    "            erreur_compte +=1\n",
    "            \n",
    "    # initialisation du décompte pour chaque état caché/observation\n",
    "    Nb_FH = 0 \n",
    "    Nb_FT = 0 \n",
    "    Nb_UH = 0\n",
    "    Nb_UT = 0\n",
    "    \n",
    "    for i in range (len(Caches)): \n",
    "        if Caches[i] == 0: \n",
    "            if Obs[i] == 0: \n",
    "                Nb_FH += 1\n",
    "            elif Obs[i] == 1: \n",
    "                Nb_FT += 1\n",
    "        else: \n",
    "            if Obs[i] == 0: \n",
    "                Nb_UH += 1\n",
    "            elif Obs[i] == 1: \n",
    "                Nb_UT += 1\n",
    "                \n",
    "\n",
    "\n",
    "    Mio[0][0] += Nb_FH/Nb_F\n",
    "    Mio[1][0] += Nb_FT/Nb_F\n",
    "    Mio[1][1] += Nb_UH/Nb_U\n",
    "    Mio[0][1] += Nb_UT/Nb_U\n",
    "    \n",
    "   \n",
    "    # estimation des probabilités initiales\n",
    "    pi0[0] = Nb_F/ (Nb_F + Nb_U)\n",
    "    pi0[1] = Nb_U/ (Nb_F + Nb_U)\n",
    "#     print(np.sum(pi0)) # la somme vaut 1, la matrice est déjà normalisée\n",
    "    \n",
    "\n",
    "    # Nous normalisons les matrices estimées\n",
    "    \n",
    "    for i in range(len(Nij)): \n",
    "        Somme = np.sum(Nij[:,i])\n",
    "        for j in range (len(Nij)): \n",
    "            Nij[j][i] = Nij[j][i] / Somme    \n",
    "\n",
    "    for i in range(len(Mio)): \n",
    "        Somme = np.sum(Mio[:,i])\n",
    "        for j in range (len(Mio)): \n",
    "            Mio[j][i] = Mio[j][i] / Somme    \n",
    "        \n",
    "    \n",
    "    return Nij, Mio, pi0\n",
    "\n",
    "Nij, Mio, pi0 = nombresOccurrence(jetsRes, 2, 2)\n",
    "\n",
    "print('Pij estimé:')\n",
    "print(Nij)\n",
    "print('\\nEio estimé:')\n",
    "print(Mio)\n",
    "print('\\npi0 estimé:')\n",
    "print(pi0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-ZYvpCgxpk3"
   },
   "source": [
    "3.2) <u> Viterbi training </u>: Écrire une fonction qui utilise\n",
    "seulement la séquence $(O_t)_{t=0:T}$ (2emme colonne de la simulation) pour estimer les\n",
    "paramètres $P_{ij}$ est $Ei(O)$. On s’arrêtera quand les différences entre les logVraissamblance est inférieur à 1e-04. Comparer les résultats de 3.1 et de 3.2 (3.2 avec plusieurs restarts,\n",
    "et avec initialisation des paramètres aléatoire).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dhKsGmO2xpk4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pij_init\n",
      " [[0.08127043 0.91872957]\n",
      " [0.83751648 0.16248352]]\n",
      "Ei_init\n",
      " [[0.4635838  0.5364162 ]\n",
      " [0.06520827 0.93479173]]\n",
      "pi0_init\n",
      " [0.38144849 0.61855151]\n",
      "-0.11541085151132773\n",
      "Pij_est\n",
      " [[0.18607544 0.81392456]\n",
      " [0.66611931 0.33388069]]\n",
      "Ei_est\n",
      " [[0.54550268 0.45449732]\n",
      " [0.53322104 0.46677896]]\n",
      "pi0_est\n",
      " [0.2802367 0.7197633]\n",
      "diff 1.1567098284840878\n",
      "Le modèle est convergé après 2 itérations.\n",
      "\n",
      "Pij estimée:\n",
      "[[0.66367209 0.35779817]\n",
      " [0.33632791 0.64220183]]\n",
      "\n",
      "Eij estimée:\n",
      "[[0.5114104  0.36391437]\n",
      " [0.4885896  0.63608563]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialisation aleatoire de Pij, Eij, pi0\n",
    "def InititRandom(nS, nO):\n",
    "    \"\"\"\n",
    "    randomly initialisations \n",
    "    input1 nS: number of states\n",
    "    input2 nO: number of observations\n",
    "    output1 Pij_init: transition probability matrix\n",
    "    output2 Ei_init: emission probability matrix\n",
    "    output3 pi0_init: initial condition \n",
    "    \"\"\"\n",
    "    random.seed(10)\n",
    "    Pji_init=np.zeros((nS,nS))\n",
    "    Ei_init=np.zeros((nO,nS))\n",
    "    pi0_init=np.zeros((nS))\n",
    "    \n",
    "    for i in range(nS):\n",
    "        pi0_init[i]=np.random.rand()\n",
    "    som=np.sum(pi0_init)\n",
    "    for i in range(nS):\n",
    "        pi0_init[i]= pi0_init[i]/som\n",
    "    for i in range(nS):\n",
    "        for j in range(nO):\n",
    "            Pji_init[i][j]=np.random.rand()\n",
    "    \n",
    "    for i in range(nO):\n",
    "        for j in range(nS):\n",
    "            Ei_init[i][j]=np.random.rand()\n",
    "           \n",
    "    for i in range(nS):\n",
    "        summ=np.sum(Pji_init[i])\n",
    "        for j in range(nO):\n",
    "             Pji_init[i][j]=Pji_init[i][j]/summ\n",
    "                \n",
    "    for i in range(nO):\n",
    "        s=np.sum(Ei_init[i])\n",
    "        for j in range(nS):\n",
    "             Ei_init[i][j]=Ei_init[i][j]/s\n",
    "\n",
    "    return Pji_init, Ei_init, pi0_init\n",
    "\n",
    "\n",
    "Pij_init, Ei_init, pi0_init=InititRandom(2, 2)\n",
    "print(\"Pij_init\\n\",Pij_init)\n",
    "print(\"Ei_init\\n\",Ei_init)\n",
    "print(\"pi0_init\\n\",pi0_init)\n",
    "\n",
    "\n",
    "\n",
    "# Calcule log Vraissamblance\n",
    "def logLikelhihood(Aij,Bij,pi0,jets):\n",
    "    \"\"\"\n",
    "    compute Log Likelihood \n",
    "    input1 Pij: transition probability matrix\n",
    "    input2 Ei: emission probability matrix\n",
    "    input3 pi0: initial condition \n",
    "    input4 jets: matrix |2xT| containing data\n",
    "    \"\"\"\n",
    "    etat_seq = jets[:,0]\n",
    "    obs_seq = jets[:,1]\n",
    "    T = len(obs_seq) #Nombre d'observations (longueur des observations)\n",
    "    lLikelihood = np.log(pi0[etat_seq[0]])\n",
    "    return lLikelihood\n",
    "\n",
    "Log_LL = logLikelhihood(Nij,Mio,pi0,jetsRes)\n",
    "print(Log_LL)\n",
    "\n",
    "\n",
    "def Training(jets, nS, nO):\n",
    "    \"\"\"\n",
    "    Viterbi Training\n",
    "    input1 jets: matrix |2xT| containing data\n",
    "    input2 nS: number of states\n",
    "    input3 nO: number of observations\n",
    "    output1 Pij_est: transition probability matrix\n",
    "    output2 Ei_est: emission probability matrix\n",
    "    output3 pi0_est: initial condition \n",
    "    output4 lLikelihood: log Likelihood\n",
    "    \"\"\"\n",
    "    jets_est = np.array(jets)  \n",
    "    Pij_est, Ei_est, pi0_est = InititRandom(nS, nO)\n",
    "    print(\"Pij_est\\n\",Pij_est)\n",
    "    print(\"Ei_est\\n\",Ei_est)\n",
    "    print(\"pi0_est\\n\",pi0_est)\n",
    "    \n",
    "    nIteration = 10000\n",
    "    criterion = 1e-04\n",
    "    lLikelihood = np.zeros((nIteration))\n",
    "    LL = []\n",
    "    \n",
    "    Val_LL_AVANT = logLikelhihood(Pij_est, Ei_est, pi0_est, jets)\n",
    "    It_star, prob = viterbi(jets,Pij_est, Ei_est,pi0_est,2,2,True)\n",
    "    Pij_est, Ei_est, pi0_est = nombresOccurrence(jets, 2, 2)       \n",
    "    Val_LL = logLikelhihood(Pij_est, Ei_est, pi0_est, jets)\n",
    "    diff = abs(Val_LL_AVANT - Val_LL)\n",
    "    print(\"diff\", diff)\n",
    "    \n",
    "    for i in range (1,nIteration): \n",
    "        if diff > criterion: \n",
    "#             print(\"vrai\")\n",
    "            It_star, prob = viterbi(jets,Pij_est, Ei_est,pi0_est,2,2,True)\n",
    "            Pij_est, Ei_est, pi0_est = nombresOccurrence(jets, 2, 2)       \n",
    "            Val_LL = logLikelhihood(Pij_est, Ei_est, pi0_est, jets)\n",
    "            LL.append(Val_LL)\n",
    "            diff = abs(Val_LL_AVANT - Val_LL)\n",
    "#             print(diff)\n",
    "            Val_LL_AVANT = Val_LL\n",
    "            \n",
    "    lLikelihood = LL\n",
    "\n",
    "    return Pij_est, Ei_est, pi0_est, lLikelihood\n",
    "    \n",
    "# #imprimer les Parametres du Viterbi Training\n",
    "Pij_est, Ei_est, pi0_est, lLikelihood = Training(jetsRes, 2, 2)\n",
    "itCount = len(lLikelihood)\n",
    "print('Le modèle est convergé après '+str(itCount)+' itérations.')\n",
    "print('\\nPij estimée:')\n",
    "print(Pij_est)\n",
    "print('\\nEij estimée:')\n",
    "print(Ei_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6B-AX8Zxpk4"
   },
   "source": [
    "<font color=\"blue\">\n",
    "Remark: Nous remarquons que nous trouvons exactement les mêmes valeurs pour les matrices estimées. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7iq2fv5xpk5"
   },
   "source": [
    "3.3) <u>Viterbi training deuxième version</u>. \n",
    "<BR>Écrivez une version de 3.2 qui:\n",
    "- part plusieurs fois (100x) d'une initialisation aléatoire desparamètres de l'HMM,\n",
    "- utilise Viterbi training pour estimer les paramètres,\n",
    "- calcul la log-vraisemblance pour les paramètres estimés,\n",
    "- sauvegarde seulement l'estimation avec la valeur maximale de lalog-vraisemblance.\n",
    "\n",
    "Qu'est-ce que vous observez?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rwS987bpxpk5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur Pij estimée:\n",
      "[]\n",
      "\n",
      "Meilleur Eij estimée:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Viterbi Training  deuxiemme version\n",
    "\n",
    "def TrainingV2(jets, nS, nO, nIterat=100):\n",
    "    \"\"\"\n",
    "    Viterbi Training version 2.0\n",
    "    input1 jets: matrix |2xT| containing data\n",
    "    input2 nS: number of states\n",
    "    input3 nO: number of observations\n",
    "    input4 nIterat: number of iterations\n",
    "    output1 Pij_best: best transition probability matrix\n",
    "    output2 Ei_best: best emission probability matrix\n",
    "    output3 pi0_best: best initial condition \n",
    "    output4 lLikelihood_best: best log Likelihood\n",
    "    \"\"\"\n",
    "\n",
    "    Pij_best = []\n",
    "    Ei_best = []\n",
    "    pi0_best = []\n",
    "    lLikelihood_best = -10000\n",
    "    \n",
    "\n",
    "    return Pij_best, Ei_best, pi0_best, lLikelihood_best\n",
    "    \n",
    "\n",
    "# Imprimer les Parametres du Viterbi Training deuxiemme version\n",
    "nIterat = 100\n",
    "Pij_best, Ei_best, pi0_best, lLikelihood_best = TrainingV2(jetsRes, 2, 2, nIterat)\n",
    "\n",
    "print('Meilleur Pij estimée:');\n",
    "print(Pij_best)\n",
    "print('\\nMeilleur Eij estimée:')\n",
    "print(Ei_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4EHk9MKxpk6"
   },
   "source": [
    "<font color=\"blue\">\n",
    "Remark:\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TME5_6_2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
